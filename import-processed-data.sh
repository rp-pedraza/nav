#!/bin/bash

ELASTICSEARCH_ADDRESS='localhost:9200'
ELASTICSEARCH_INDEX_ADDRESS=${ELASTICSEARCH_ADDRESS}/nmap_scans
ELASTICSEARCH_INDEX_TYPE_ADDRESS=${ELASTICSEARCH_INDEX_ADDRESS}/default
PROCESSED_DATA_LOCATION='./data.processed'

function fail {
	echo "$1" >&2
	exit 1
}

[[ ! -d ${PROCESSED_DATA_LOCATION} ]] && fail "${PROCESSED_DATA_LOCATION} does not exist."

DATA=("${PROCESSED_DATA_LOCATION}"/*.json)

[[ ${#DATA[@]} -eq 0 ]] && fail "No data found in ${PROCESSED_DATA_LOCATION}."

if read -p "This will delete existing data. Continue? [Y/N] " && [[ ${REPLY} == [yY] ]]; then
	# Delete existing data.

	echo "Removing old index."
	echo "Please ignore 'no such index' error."
	curl -XDELETE "${ELASTICSEARCH_INDEX_ADDRESS}" || fail "Failed to delete existing index."
	echo

	# Setup new index.
	#
	# See https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-nested-query.html
	# and https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html
	# for info about 'nested' type.

	echo "Setting up mappings."

	curl -XPUT "${ELASTICSEARCH_INDEX_ADDRESS}" -d '{
		"mappings" : {
			"default" : {
				"properties" : {
					"datetime" : { "type" : "double" },
					"hostnames": { "type" : "nested" }
				}
			}
		}
	}' || fail "Failed to setup mappings."

	echo

	# Upload content.

	I=0

	for FILE in "${PROCESSED_DATA_LOCATION}"/*.json; do
		echo "Importing ${FILE}."

		JSON_STR=$(<"${FILE}")

		# If we want to use hash-like autogenerated IDs:
		# curl -XPOST localhost:9200/nmap_scans/default/ -H'Content-Type: application/json' -d"${JSON_STR}"

		curl -XPUT "${ELASTICSEARCH_INDEX_TYPE_ADDRESS}/$(( ++I ))" -H'Content-Type: application/json' -d"${JSON_STR}" || {
			fail "Failed to upload data to index: "$'\n'"${JSON_STR}"
			break
		}

		echo
	done
fi
